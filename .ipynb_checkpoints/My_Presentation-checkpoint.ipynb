{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# V2 Neural Processing of V2 Neurons\n",
    "\n",
    "### By: Brian Kagel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Background\n",
    "\n",
    "In the mammalian visual system, there exists a hierarchy of subcortical and cortical regions to represent increasingly complex properties of a retinal image. To better understand this hierarchy and how the brain interprets fine details of images, it is important to understand the mechanisms of information transfer between systems. Current models describe how neurons in the primary visual cortex (V1) respond to stimuli and that these V1 neurons primarily project to area V2. However, no current model describes how V2 encodes the details of natural images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## V2 Neurons\n",
    "\n",
    "Previous studies suggest V2 neurons are very similar to V1, while contrasting studies suggest V2 neurons are sensitive to higher-order stimulus properties that represent the finer details of images (texture, shading, contours, etc). Essentially, it is unclear whether V2 system is simply a relay of information or represent higher cognitive processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Primary Literature Findings\n",
    "\n",
    "Using individual probing techniques and experimental designs that consisted of presenting various natural images and measuring responses, the authors were able to contruct quantitative models of the V2 system. Using neuronal responses, the authors estimated a nonlinear spatiotemporal receptive field (STRF) for each neuron. This model provided great detail as far as the purpose of individual neurons and can be used as a comparison tool to other V1 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### BWT Models (Berkeley Wavelet Transform)\n",
    "<img src=\"images/bw_model.png\" alt=\"bw_model\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### BWT-STRF Model\n",
    "\n",
    "<img src=\"images/strf_model.png\" alt=\"strf_model\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Results\n",
    "\n",
    "<img src=\"images/neuron_results.png\" alt=\"neuron_results\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Results\n",
    "\n",
    "Researchers were able to discover that there exist two subclasses of neurons in the V2 system, one that is functionally similar to V1 and one that is distinct. Both V1 and V2 have similar excitatory spatial tuning profiles, but the distinct class have strong supressive spatial tuning that isn't seen in V1. This discover of a new class of neurons was very exciting and opened the door for a lot of future research proposals to better understand how the brain is able to process images coming from the visual cortex. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## My Proposal\n",
    "\n",
    "Using the data collected in this experiment, I would like to further investigate the response characteristics that this new class of V2 neurons have when presented with a visual stimulus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## My Proposal\n",
    "\n",
    "I will measuring the intensity of the image (likeness to orientation) against the response intensity (spike counts) for that V2 neuron.  I will then take statistical measures within each trial number for both stimulus presentation strength and response strength and compare the two together, looking for variations both within trial and across trials. Measures include maximum, mean, and standard deviation of responses. This will be repeated over two seperate experiments (two seperate neurons)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## My Proposal\n",
    "\n",
    "I believe that being able to graphically display the response of this class of neurons as it relates to stimulus presentation would provide a helpful context to how this new class operates when presented a stimulus. Measuring variation in this way, we can get a better sense of how sporadic/fine-tuned these neurons are, where within trial variability represents accuracy and across trial representing consistency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hypothesis\n",
    "\n",
    "I hypothesize that within trials, there should be a very tight correlation between presentation and response. V2 neurons are after all reported to be a more fine-detailed version of V1 neurons.\n",
    "\n",
    "I also hypothesize that across trials, I will see even less variation than the within trials. This is because across trials pulls together more data points and should be a more accurate representation of the system as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Methods\n",
    "\n",
    "Each dataset represents one experiement, I decided to pull two different datasets for this purpose as it would allow repetition. \n",
    "\n",
    "<img src=\"images/data_function.png\" alt=\"data_function\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I then used the function above to import the data into my notebook. Defining exp1 and exp2 as V2 and V2_2.\n",
    "\n",
    "<img src=\"images/data_function.png\" alt=\"data_function\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I used the dict.keys function to reveal the subsections within the experiements. Using the information provided in the CRCNS README file as well as opening up and exploring each section, I found that 'spiketime' and 'phototime' were not only the only sections with tangible data, but represented standardized and normalized stimulus and response intesntity respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/exp1_chart.png\" alt=\"exp1_chart\" style=\"width: 400px;\"/>\n",
    "\n",
    "<img src=\"images/exp2_chart.png\" alt=\"exp2_chart\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To organize the data into lists I can easily access and understand, I used Pandas and the code below:\n",
    "\n",
    "<img src=\"images/pandas.png\" alt=\"pandas\" style=\"width: 1200px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I then used a For loop to iterate through the panda lists to calculate data for the Within Trial. \n",
    "\n",
    "<img src=\"images/for_loop.png\" alt=\"for_loop\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After repeating for Exp2, I then used the code below to compute data across trials:\n",
    "\n",
    "<img src=\"images/across_code.png\" alt=\"across_code\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results\n",
    "\n",
    "For over 60 trials and 3 different statistical measurements, this printed a lot of results. To get a better visual of the information to draw inferences from, I displayed the results graphically using the code below:\n",
    "\n",
    "<img src=\"images/result_code.png\" alt=\"result_code\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results for Mean\n",
    "\n",
    "<img src=\"images/mean_plot.png\" alt=\"mean_plot\" style=\"width: 700px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results for Max\n",
    "\n",
    "<img src=\"images/max_plot.png\" alt=\"max_plot\" style=\"width: 700px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results for Standard Deviations\n",
    "\n",
    "<img src=\"images/std_plot.png\" alt=\"std_plot\" style=\"width: 700px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discussion\n",
    "\n",
    "Overall, I was surprised by how much variation that was actually present as a difference between stimulus and response intensities. Although I hypothesized that the variation across trials would be less than the average within trials, it turns out to be the opposite effect. There was also great variation between experiments as well that was not noticed until I plotted them against each other. This variation is interesting because I believe that it highlights the sporatic nature of not only the new class of V2 neurons, but neural systems in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discussion\n",
    "\n",
    "Limitations included 'spiketime' and 'phototime' being the only variables available for use. These were the only data available in the file (a MatLab file at that) and they were rather confusing data to interpret at first. I believe that if the raw data was provided (not normalized or standardized) I could have made data computations that were easier to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discussion\n",
    "\n",
    "Next steps I believe would be to further investigate the response characteristics of this class of V2 neurons. As a newly discovered class, there is a lot to be learned as far as mechanisms and functionality goes. Given the opportunity, I would have done a similar process, comparing the differences of perhaps first spike occurances vs stimulus presentation on a time axis. I think measuring this speed factor would also turn in interesting results. Or even to compare characteristics to V1 neurons like in the primary literature would also be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Acknowledgments\n",
    "\n",
    "I would like to acknowledge classmates Robert Michaels and Lasya Pidaparthi for helping answer some design and coding questions.\n",
    "\n",
    "Professor Meliza for also helping answer questions, especially about GitHub and uploading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Acknowledgments\n",
    "\n",
    "Finally, primary literature authors Ben Willmore, Ryan Prenger, and Jack Gallant for providing the original data in the first place and conducting the background experiments.\n",
    "\n",
    "\"Neural Representation of Natural Images in Visual Area V2\"\n",
    "Link to Paper: https://www.ncbi.nlm.nih.gov/pubmed/20147538 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions\n",
    "\n",
    "Thank you for listening. Any questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
